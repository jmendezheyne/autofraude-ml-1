{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "#pip install \"gpt4all[cuda]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/Grabaciones/56507943/transcriptions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_json_a_texto_con_tiempo(ruta_archivo_json):\n",
    "    # Cargar el archivo JSON\n",
    "    with open(ruta_archivo_json, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Inicializar variables\n",
    "    primer_timestamp = None\n",
    "    transcripciones = []\n",
    "\n",
    "    # Procesar transcripciones\n",
    "    for transcript in data.get(\"transcripts\", []):\n",
    "        for phrase in transcript.get(\"phrases\", []):\n",
    "            speaker = \"Ejecutivo\" if phrase.get(\"participantPurpose\") == \"internal\" else \"Cliente\"\n",
    "            text = phrase.get(\"text\", \"\").strip()\n",
    "            start_time_ms = phrase.get(\"startTimeMs\", 0)\n",
    "\n",
    "            if primer_timestamp is None:\n",
    "                primer_timestamp = start_time_ms\n",
    "\n",
    "            tiempo_normalizado_ms = start_time_ms - primer_timestamp\n",
    "            minutos = (tiempo_normalizado_ms // 1000) // 60\n",
    "            segundos = (tiempo_normalizado_ms // 1000) % 60\n",
    "            tiempo_formateado = f\"{minutos:02}:{segundos:02}\"\n",
    "\n",
    "            if text:\n",
    "                transcripciones.append(f\"[{tiempo_formateado}] {speaker}: {text}\")\n",
    "\n",
    "    transcripcion_procesada = \"\\n\".join(transcripciones)\n",
    "\n",
    "    # Generar ruta de salida reemplazando la extensi√≥n con \"_transcripcion_texto.txt\"\n",
    "    ruta_salida = os.path.splitext(ruta_archivo_json)[0] + \"_texto.txt\"\n",
    "\n",
    "    # Guardar resultado\n",
    "    with open(ruta_salida, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(transcripcion_procesada)\n",
    "\n",
    "    print(f\"‚úÖ Transcripci√≥n corregida y guardada en: {ruta_salida}\")\n",
    "\n",
    "    return ruta_salida\n",
    "\n",
    "# Ejemplo de uso:\n",
    "#ruta_transcripcion_texto = convertir_json_a_texto_con_tiempo(path+\"transription_0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de frases comunes de grabadora que queremos eliminar\n",
    "frases_grabadora = [\n",
    "    \"tu llamada es importante para nosotros\",\n",
    "    \"presentamos un alto flujo de llamadas\",\n",
    "    \"te agradecemos permanecer en l√≠nea\",\n",
    "    \"espera de atenci√≥n de un ejecutivo\",\n",
    "    \"nunca te llamaremos para pedir tus claves\",\n",
    "    \"nunca te enviaremos link por correo\",\n",
    "    \"ingresar a tu banca en l√≠nea\",\n",
    "]\n",
    "\n",
    "def eliminar_frases_grabadora_archivo(ruta_archivo_entrada, frases_eliminar):\n",
    "    # üìå Funci√≥n interna que realiza el filtrado de frases\n",
    "    def eliminar_frases(texto, frases):\n",
    "        lineas = texto.split(\"\\n\")\n",
    "        lineas_filtradas = []\n",
    "\n",
    "        for linea in lineas:\n",
    "            # Elimina timestamp y etiquetas iniciales si existen (formato flexible)\n",
    "            contenido = re.sub(r\"^\\[?\\d{0,2}:\\d{0,2}\\]?\\s?(Ejecutivo|Cliente)?\\s?:?\", \"\", linea).strip()\n",
    "\n",
    "            if not any(frase in contenido.lower() for frase in frases):\n",
    "                lineas_filtradas.append(linea)\n",
    "\n",
    "        return \"\\n\".join(lineas_filtradas)\n",
    "\n",
    "    # Leer archivo original\n",
    "    with open(ruta_archivo_entrada, \"r\", encoding=\"utf-8\") as file:\n",
    "        transcripcion = file.read()\n",
    "\n",
    "    # Eliminar frases grabadora\n",
    "    transcripcion_limpia = eliminar_frases(transcripcion, frases_eliminar)\n",
    "\n",
    "    # Generar archivo de salida autom√°ticamente\n",
    "    ruta_archivo_salida = os.path.splitext(ruta_archivo_entrada)[0] + \"_sin_grabadora.txt\"\n",
    "\n",
    "    # Guardar el resultado limpio\n",
    "    with open(ruta_archivo_salida, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(transcripcion_limpia)\n",
    "\n",
    "    print(f\"‚úÖ Transcripci√≥n limpia guardada en: {ruta_archivo_salida}\")\n",
    "    return ruta_archivo_salida\n",
    "\n",
    "# Ejemplo de c√≥mo usar esta funci√≥n:\n",
    "#ruta_resultado_sin_grabadora = eliminar_frases_grabadora_archivo(ruta_transcripcion_texto, frases_grabadora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "\n",
    "def limpiar_stopwords_transcripcion(ruta_archivo_entrada):\n",
    "    # Descargar stopwords de NLTK (solo la primera vez)\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "\n",
    "    # Cargar stopwords en espa√±ol\n",
    "    stop_words = set(stopwords.words(\"spanish\"))\n",
    "\n",
    "    # Lista personalizada para conservar palabras importantes en an√°lisis de fraude\n",
    "    stopwords_permitidas = {\"si\", \"s√≠\", \"no\", \"tarjeta\", \"clave\", \"fraude\", \"banco\", \"dinero\", \n",
    "                            \"transferencia\", \"pago\", \"cuenta\", \"solamente\", \"solo\", \"sola\", \"solas\", \n",
    "                            \"solos\", \"mi\"}\n",
    "    \n",
    "    # Remover las permitidas de la lista original\n",
    "    stop_words = stop_words - stopwords_permitidas\n",
    "\n",
    "    # Funci√≥n interna para limpiar texto\n",
    "    def limpiar_texto(texto, stop_words):\n",
    "        palabras = texto.split()\n",
    "        palabras_filtradas = [palabra for palabra in palabras if palabra.lower() not in stop_words]\n",
    "        return \" \".join(palabras_filtradas)\n",
    "\n",
    "    # Cargar archivo original\n",
    "    with open(ruta_archivo_entrada, \"r\", encoding=\"utf-8\") as file:\n",
    "        transcripcion = file.read()\n",
    "\n",
    "    # Aplicar limpieza\n",
    "    transcripcion_limpia = limpiar_texto(transcripcion, stop_words)\n",
    "\n",
    "    # Crear ruta de salida autom√°ticamente\n",
    "    ruta_salida = os.path.splitext(ruta_archivo_entrada)[0] + \"_sin_stopwords.txt\"\n",
    "\n",
    "    # Guardar resultado limpio\n",
    "    with open(ruta_salida, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(transcripcion_limpia)\n",
    "\n",
    "    print(f\"‚úÖ Transcripci√≥n sin stopwords guardada en: {ruta_salida}\")\n",
    "\n",
    "    return ruta_salida\n",
    "\n",
    "# Ejemplo de c√≥mo usar la funci√≥n:\n",
    "#ruta_resultado_sin_stopwords = limpiar_stopwords_transcripcion(ruta_resultado_sin_grabadora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def buscar_entrega_con_contexto(ruta_entrada, contexto):\n",
    "    \"\"\"\n",
    "    Busca palabras relacionadas con 'entregar' o 'compartir' y extrae segmentos con contexto.\n",
    "\n",
    "    Par√°metros:\n",
    "    - ruta_entrada (str): Ruta al archivo de texto de entrada.\n",
    "    - contexto (int): N√∫mero de caracteres antes y despu√©s del match.\n",
    "\n",
    "    Retorna:\n",
    "    - ruta_salida (str): Ruta del archivo generado.\n",
    "    - resultados (list): Lista de segmentos encontrados.\n",
    "    \"\"\"\n",
    "    with open(ruta_entrada, \"r\", encoding=\"utf-8\") as file:\n",
    "        texto = file.read()\n",
    "\n",
    "    # Patr√≥n para buscar entreg√≥, entrega, entregado, compart√≠, comparti√≥, etc.\n",
    "    patron = re.compile(r\"\\b(entreg[a-z√°√©√≠√≥√∫]*|compart[a-z√°√©√≠√≥√∫]*)\\b\", re.IGNORECASE)\n",
    "\n",
    "    resultados = []\n",
    "    for match in patron.finditer(texto):\n",
    "        inicio = max(match.start() - contexto, 0)\n",
    "        fin = min(match.end() + contexto, len(texto))\n",
    "        segmento = texto[inicio:fin].strip()\n",
    "        resultados.append(segmento)\n",
    "\n",
    "    # Guardar el resultado\n",
    "    carpeta = os.path.dirname(ruta_entrada)\n",
    "    ruta_salida = os.path.join(carpeta, \"segmentos_entrega_contexto.txt\")\n",
    "    with open(ruta_salida, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"\\n---\\n\".join(resultados))\n",
    "\n",
    "    print(f\"‚úÖ Segmentos guardados en: {ruta_salida}\")\n",
    "    return ruta_salida, resultados\n",
    "\n",
    "#ruta_salida, segmentos = buscar_entrega_con_contexto(ruta_resultado_sin_stopwords,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from gpt4all import GPT4All\n",
    "\n",
    "def analizar_clave_con_gpt4all(ruta_transcripcion):\n",
    "    \"\"\"\n",
    "    Analiza si un cliente entreg√≥ claves a un tercero usando un modelo GPT4All.\n",
    "\n",
    "    Retorna:\n",
    "    - respuesta generada por el modelo (texto)\n",
    "    \"\"\"\n",
    "\n",
    "    ruta_modelo = \"C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/mistral-7b-instruct-v0.2.Q4_K_M.gguf\"    \n",
    "    # üìå Inicializar el modelo\n",
    "    model = GPT4All(ruta_modelo, device='cuda')\n",
    "\n",
    "    # üìå Cargar la transcripci√≥n\n",
    "    with open(ruta_transcripcion, 'r', encoding='utf-8') as archivo:\n",
    "        transcripcion = archivo.read()\n",
    "\n",
    "    # üìå Mostrar el largo en caracteres\n",
    "    print(f\"Largo de la transcripci√≥n: {len(transcripcion)} caracteres\")\n",
    "\n",
    "    # üìå Formatear el prompt\n",
    "    prompt = f\"\"\"\n",
    "    [INST]\n",
    "    Eres un analista experto en detecci√≥n de fraude bancario. Tu tarea es revisar con mucho cuidado la conversaci√≥n telef√≥nica entre un EJECUTIVO y un CLIENTE que presenta un reclamo por fraude.\n",
    "\n",
    "    Debes determinar estrictamente si el CLIENTE reconoce o indica expl√≠citamente haber entregado, compartido o revelado cualquier clave, contrase√±a, c√≥digo o informaci√≥n confidencial (directa o indirectamente) a alguna persona (incluyendo claramente familiares, terceros, conocidos o desconocidos).\n",
    "\n",
    "    IMPORTANTE: Si el cliente menciona expl√≠citamente haber entregado claves o informaci√≥n confidencial a alguna persona, aunque sea un familiar (como \"mi hija\", \"mi hijo\", \"mi esposo/a\", etc.), debes responder obligatoriamente \"S√ç\". \n",
    "\n",
    "    Instrucciones para tu respuesta:\n",
    "    - Primera l√≠nea: escribe √∫nicamente \"S√ç\" o \"NO\".\n",
    "    - Segunda l√≠nea: Explica brevemente la raz√≥n espec√≠fica bas√°ndote literalmente en lo que dijo el cliente en la conversaci√≥n (usa citas textuales del cliente).\n",
    "\n",
    "    CONVERSACI√ìN:\n",
    "    {transcripcion}\n",
    "\n",
    "    RESPUESTA:\n",
    "    [/INST]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üïí Comienzo del an√°lisis:\", datetime.now())\n",
    "\n",
    "    # üìå Generar respuesta\n",
    "    respuesta = model.generate(prompt).strip()\n",
    "    return respuesta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_respuesta_binaria(respuesta_modelo):\n",
    "    \"\"\"\n",
    "    Extrae si la respuesta del modelo comienza con \"S√ç\" o \"NO\".\n",
    "\n",
    "    Par√°metros:\n",
    "    - respuesta_modelo (str): Texto completo generado por el modelo.\n",
    "\n",
    "    Retorna:\n",
    "    - \"SI\" o \"NO\" (en may√∫sculas) seg√∫n la primera l√≠nea de la respuesta.\n",
    "    \"\"\"\n",
    "    primera_linea = respuesta_modelo.strip().splitlines()[0].strip().upper()\n",
    "    \n",
    "    if primera_linea.startswith((\"S√ç\", \"SI\")):\n",
    "        return \"SI\"\n",
    "    elif primera_linea.startswith(\"NO\"):\n",
    "        return \"NO\"\n",
    "    else:\n",
    "        return \"NO DEFINIDO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_general = 'C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/Grabaciones/'\n",
    "#rut = '56589062'\n",
    "#path_final = path_general + rut + '/transcriptions/'\n",
    "# Ruta Transcripciones\n",
    "#path = 'C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/Grabaciones/58211507/transcriptions/'\n",
    "\n",
    "#Conviertiendo de JSON a TXT\n",
    "#ruta_transcripcion_texto = convertir_json_a_texto_con_tiempo(path_final+\"transription_0.json\")\n",
    "\n",
    "# Quitando Transcripci√≥n de Grabadora\n",
    "#ruta_resultado_sin_grabadora = eliminar_frases_grabadora_archivo(ruta_transcripcion_texto, frases_grabadora)\n",
    "\n",
    "#Limpiando Stopwords\n",
    "#ruta_resultado_sin_stopwords = limpiar_stopwords_transcripcion(ruta_resultado_sin_grabadora)\n",
    "\n",
    "#ruta_salida, segmentos = buscar_entrega_con_contexto(ruta_resultado_sin_stopwords,200)\n",
    "\n",
    "#print(\"Rut :\" + rut)\n",
    "\n",
    "#respuesta = analizar_clave_con_gpt4all(ruta_salida)\n",
    "#print(\"üìå Respuesta del modelo:\")\n",
    "#print(respuesta)\n",
    "\n",
    "#respuesta_consolidada = extraer_respuesta_binaria(respuesta)\n",
    "#print(respuesta_consolidada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def procesar_grabaciones_y_guardar_excel(carpeta_general, ruta_excel_salida):\n",
    "    \"\"\"\n",
    "    Recorre todas las subcarpetas de la carpeta de Grabaciones, ejecuta el pipeline\n",
    "    de an√°lisis y guarda las respuestas en un Excel consolidado.\n",
    "    \"\"\"\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for rut in os.listdir(carpeta_general):\n",
    "        path_final = os.path.join(carpeta_general, rut, \"transcriptions\")\n",
    "\n",
    "        # Verifica que exista el archivo de transcripci√≥n\n",
    "        archivo_json = os.path.join(path_final, \"transription_0.json\")\n",
    "        if not os.path.exists(archivo_json):\n",
    "            print(f\"‚ö†Ô∏è No se encontr√≥ transription_0.json para RUT {rut}, se omite.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Paso a paso del procesamiento\n",
    "            ruta_transcripcion_texto = convertir_json_a_texto_con_tiempo(archivo_json)\n",
    "            ruta_sin_grabadora = eliminar_frases_grabadora_archivo(ruta_transcripcion_texto, frases_grabadora)\n",
    "            ruta_sin_stopwords = limpiar_stopwords_transcripcion(ruta_sin_grabadora)\n",
    "            ruta_segmentos, segmentos = buscar_entrega_con_contexto(ruta_sin_stopwords, 200)\n",
    "\n",
    "            print(segmentos)-\n",
    "            respuesta = analizar_clave_con_gpt4all(ruta_segmentos)\n",
    "            binaria = extraer_respuesta_binaria(respuesta)\n",
    "\n",
    "            registros.append({\n",
    "                \"RUT\": rut,\n",
    "                \"Respuesta\": binaria,\n",
    "                \"Explicaci√≥n\": respuesta,\n",
    "                \"Segmentos Detectados\": len(segmentos)\n",
    "            })\n",
    "\n",
    "            print(f\"‚úÖ Procesado RUT {rut} - Respuesta: {binaria}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error al procesar RUT {rut}: {e}\")\n",
    "\n",
    "    # Guardar Excel final\n",
    "    df = pd.DataFrame(registros)\n",
    "    df.to_excel(ruta_excel_salida, index=False)\n",
    "    print(f\"üìÅ Excel consolidado guardado en: {ruta_excel_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transcripci√≥n corregida y guardada en: C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/Grabaciones\\58293900\\transcriptions\\transription_0_texto.txt\n",
      "‚úÖ Transcripci√≥n limpia guardada en: C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/Grabaciones\\58293900\\transcriptions\\transription_0_texto_sin_grabadora.txt\n",
      "‚úÖ Transcripci√≥n sin stopwords guardada en: C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/Grabaciones\\58293900\\transcriptions\\transription_0_texto_sin_grabadora_sin_stopwords.txt\n",
      "‚úÖ Segmentos guardados en: C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/Grabaciones\\58293900\\transcriptions\\segmentos_entrega_contexto.txt\n",
      "[]\n",
      "Largo de la transcripci√≥n: 0 caracteres\n",
      "üïí Comienzo del an√°lisis: 2025-04-08 21:45:28.249489\n",
      "‚úÖ Procesado RUT 58293900 - Respuesta: SI\n",
      "üìÅ Excel consolidado guardado en: C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/resultados_fraude.xlsx\n"
     ]
    }
   ],
   "source": [
    "carpeta_base = \"C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/Grabaciones\"\n",
    "excel_destino = \"C:/Users/jmend/OneDrive/Escritorio/Magister/Capstone/NLP/resultados_fraude.xlsx\"\n",
    "\n",
    "procesar_grabaciones_y_guardar_excel(carpeta_base, excel_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
